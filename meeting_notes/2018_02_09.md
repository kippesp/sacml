# Minutes

## Next Time

- One more week of the Titanic problem, so we need a volunteer to present.
- May review this entry mentioned briefly today: [improving the
  score to 0.813](https://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)

## Summary

- Walked through Paul's fork of the tutorial by [Helge
  Bjorland](https://www.kaggle.com/helgejo/an-interactive-data-science-tutorial)
  with additional, high-level, contrasts from Scott's fork of the tutorial by
  [Manav Sehgal](https://www.kaggle.com/startupsci/titanic-data-science-solutions)
- Interacting with the notebook
- How test/train were combined and later split
- Examining some of the help functions from the author
- Visualizing and examining the data
- Meta variables
- Choosing one of the tested models (good accuracy while not obviously
  overfitting)
- Examined errors from Paul's model.
    - Since an output file was generated, probably not a big deal.
    - The score of 0.0000 probably because the .csv file was malformed and used
      floats for the survival column rather than an integer type.

## On-Going Questions

- The Titanic competition ends in 2020.  How is the withheld dataset injected
  into a notebook's solution?
- What would a data scientist do if the test set shows the model needs more
  work?  Adjusting the model would result in leakage from the validation set.
  How is this effect avoided?
